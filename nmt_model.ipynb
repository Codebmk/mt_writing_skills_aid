{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Codebmk/mt_writing_skills_aid/blob/main/nmt_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b88c2d5"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn\n",
        "!pip install nltk\n",
        "!pip install datasets\n",
        "!pip install keras_nlp\n",
        "!pip install rouge-score\n",
        "\n",
        "import logging\n",
        "import time\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datasets\n",
        "import tensorflow as tf\n",
        "import keras_nlp\n",
        "import pathlib\n",
        "import random\n",
        "import json\n",
        "from tensorflow import keras\n",
        "from tensorflow_text.tools.wordpiece_vocab import (\n",
        "    bert_vocab_from_dataset as bert_vocab,\n",
        ")\n",
        "from keras_nlp.metrics import Bleu\n",
        "from IPython import display\n",
        "display.clear_output()"
      ],
      "id": "3b88c2d5"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c78c1017"
      },
      "outputs": [],
      "source": [
        "# define our parameters/hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 1\n",
        "MAX_SEQUENCE_LENGTH = 128\n",
        "ENG_VOCAB_SIZE = 15000\n",
        "LUG_VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 256\n",
        "INTERMEDIATE_DIM = 2048\n",
        "NUM_HEADS = 8"
      ],
      "id": "c78c1017"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "252da6b2",
        "outputId": "aacb319d-2838-4fd1-e5a7-b30cb4917b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23947 training pairs\n",
            "500 validation pairs\n",
            "500 test pairs\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the SALT dataset for English and Luganda\n",
        "train_data = []\n",
        "test_data = []\n",
        "val_data = []\n",
        "\n",
        "with open('./sample_data/salt-train-v1.1.jsonl', 'r') as file:\n",
        "    for line in file:\n",
        "        train_data.append(json.loads(line))\n",
        "with open('./sample_data/salt-test-v1.1.jsonl', 'r') as file:\n",
        "    for line in file:\n",
        "        test_data.append(json.loads(line))\n",
        "with open('./sample_data/salt-dev-v1.1.jsonl', 'r') as file:\n",
        "    for line in file:\n",
        "        val_data.append(json.loads(line))\n",
        "\n",
        "train_set = []\n",
        "test_set = []\n",
        "val_set = []\n",
        "\n",
        "# Access the train, test and validation split of the dataset\n",
        "for item in train_data:\n",
        "    eng_text = item['text']['eng']\n",
        "    lug_text = item['text']['lug']\n",
        "    train_set.append((str(eng_text), str(lug_text)))\n",
        "for item in test_data:\n",
        "    eng_text = item['text']['eng']\n",
        "    lug_text = item['text']['lug']\n",
        "    test_set.append((str(eng_text), str(lug_text)))\n",
        "for item in val_data:\n",
        "    eng_text = item['text']['eng']\n",
        "    lug_text = item['text']['lug']\n",
        "    val_set.append((str(eng_text), str(lug_text)))\n",
        "\n",
        "# Extract the sentence pairs from the dataset split\n",
        "train_pairs = [(data[0].lower(), data[1].lower()) for data in train_set]\n",
        "test_pairs = [(data[0].lower(), data[1].lower()) for data in test_set]\n",
        "val_pairs = [(data[0].lower(), data[1].lower()) for data in val_set]\n",
        "\n",
        "print(f\"{len(train_set)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "id": "252da6b2"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "40e7471a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# tokenize the data\n",
        "def train_word_piece(text_samples, vocab_size, reserved_tokens):\n",
        "    word_piece_ds = tf.data.Dataset.from_tensor_slices(text_samples)\n",
        "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "        word_piece_ds.batch(1000).prefetch(2),\n",
        "        vocabulary_size=vocab_size,\n",
        "        reserved_tokens=reserved_tokens,\n",
        "    )\n",
        "    return vocab"
      ],
      "id": "40e7471a"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cbf96d92"
      },
      "outputs": [],
      "source": [
        "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
        "\n",
        "eng_samples = [text_pair[0] for text_pair in train_pairs]\n",
        "eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n",
        "\n",
        "lug_samples = [text_pair[1] for text_pair in train_pairs]\n",
        "lug_vocab = train_word_piece(lug_samples, LUG_VOCAB_SIZE, reserved_tokens)"
      ],
      "id": "cbf96d92"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e418039f",
        "outputId": "88766a8c-fc5e-4f00-b443-e8cfb94e538f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Tokens:  ['by', 'been', 'can', 'do', 'one', 'all', 'school', 'how', 'our', 'an']\n",
            "Luganda Tokens:  ['okukola', 'za', 'abakulembeze', 'bwa', 'wange', 'eggwanga', 'ka', 'waliwo', 'ttiimu', 'gye']\n"
          ]
        }
      ],
      "source": [
        "print(\"English Tokens: \", eng_vocab[100:110])\n",
        "print(\"Luganda Tokens: \", lug_vocab[100:110])"
      ],
      "id": "e418039f"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "247afc11"
      },
      "outputs": [],
      "source": [
        "eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=eng_vocab, lowercase=False\n",
        ")\n",
        "lug_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=lug_vocab, lowercase=False\n",
        ")"
      ],
      "id": "247afc11"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5914800b",
        "outputId": "66027624-8053-4b3b-84fa-318051be42d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English sentence:  it was not a ghost refugee camp.\n",
            "Tokens:  tf.Tensor([  91   69   76   24   30  497 2967  182  531 1453   10], shape=(11,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b'it was not a ghost refugee camp .', shape=(), dtype=string)\n",
            "\n",
            "Luganda sentence:  enkambi y'abanoonyiboobubudamu teyaliiwo mu bulimba.\n",
            "Tokens:  tf.Tensor([2030   48    6  212 2959 2082   52   66  173    9], shape=(10,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b\"enkambi y ' abanoonyiboobubudamu teyaliiwo mu bulimba .\", shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "eng_input_ex = train_pairs[0][0]\n",
        "eng_tokens_ex = eng_tokenizer.tokenize(eng_input_ex)\n",
        "print(\"English sentence: \", eng_input_ex)\n",
        "print(\"Tokens: \", eng_tokens_ex)\n",
        "print(\n",
        "    \"Recovered text after detokenizing: \",\n",
        "    eng_tokenizer.detokenize(eng_tokens_ex),\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "lug_input_ex = train_pairs[0][1]\n",
        "lug_tokens_ex = lug_tokenizer.tokenize(lug_input_ex)\n",
        "print(\"Luganda sentence: \", lug_input_ex)\n",
        "print(\"Tokens: \", lug_tokens_ex)\n",
        "print(\n",
        "    \"Recovered text after detokenizing: \",\n",
        "    lug_tokenizer.detokenize(lug_tokens_ex),\n",
        ")"
      ],
      "id": "5914800b"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "23a40d98"
      },
      "outputs": [],
      "source": [
        "def preprocess_batch(eng, lug):\n",
        "    batch_size = tf.shape(lug)[0]\n",
        "\n",
        "    eng = eng_tokenizer(eng)\n",
        "    lug = lug_tokenizer(lug)\n",
        "\n",
        "    # Pad `eng` to `MAX_SEQUENCE_LENGTH`.\n",
        "    eng_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "    eng = eng_start_end_packer(eng)\n",
        "\n",
        "    # Add special tokens (`\"[START]\"` and `\"[END]\"`) to `lug` and pad it as well.\n",
        "    lug_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n",
        "        start_value=lug_tokenizer.token_to_id(\"[START]\"),\n",
        "        end_value=lug_tokenizer.token_to_id(\"[END]\"),\n",
        "        pad_value=lug_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "    lug = lug_start_end_packer(lug)\n",
        "\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": lug[:, :-1],\n",
        "        },\n",
        "        lug[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, lug_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    lug_texts = list(lug_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, lug_texts))\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "id": "23a40d98"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83023b1d",
        "outputId": "ba81c223-d0d3-41c4-b830-344f9405244f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 128)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 128)\n",
            "targets.shape: (64, 128)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "id": "83023b1d"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e4f8c6a4"
      },
      "outputs": [],
      "source": [
        "## Building the model\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=ENG_VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_outputs = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=LUG_VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(decoder_inputs)\n",
        "\n",
        "x = keras_nlp.layers.TransformerDecoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs = keras.layers.Dense(LUG_VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "decoder = keras.Model(\n",
        "    [\n",
        "        decoder_inputs,\n",
        "        encoded_seq_inputs,\n",
        "    ],\n",
        "    decoder_outputs,\n",
        ")\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs],\n",
        "    decoder_outputs,\n",
        "    name=\"transformer\",\n",
        ")"
      ],
      "id": "e4f8c6a4"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e3c8467c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ],
      "id": "e3c8467c"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea130e98",
        "outputId": "6a5b1bb5-56df-48a8-845f-17a83240f233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " token_and_position_embedding (  (None, None, 256)   3872768     ['encoder_inputs[0][0]']         \n",
            " TokenAndPositionEmbedding)                                                                       \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   1315072     ['token_and_position_embedding[0]\n",
            " erEncoder)                                                      [0]']                            \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 15000)  9306520     ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,494,360\n",
            "Trainable params: 14,494,360\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "375/375 [==============================] - 4083s 11s/step - loss: 5.3835 - accuracy: 0.2561 - val_loss: 4.6652 - val_accuracy: 0.2983\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model and store the history\n",
        "history = transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=[early_stopping])"
      ],
      "id": "ea130e98"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8KbEWKmBio0V"
      },
      "outputs": [],
      "source": [
        "transformer.save(\"./best_models/nmt_transformer1.h5\")"
      ],
      "id": "8KbEWKmBio0V"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c8c942c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86df6668-939e-493d-91c0-47eb8fec0655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Example 0 **\n",
            "every christian should contribute what he can afford to the construction of the church.\n",
            "abantu baaaawuuuuutaase .\n",
            "\n",
            "** Example 1 **\n",
            "the impact is at their manufacturing and distribution points.\n",
            "abantu baaaawuuuuutaase .\n",
            "\n",
            "** Example 2 **\n",
            "there is a lot of disagreement within the party.\n",
            "abantu bangi baaawuuuuutaase .\n",
            "\n",
            "** Example 3 **\n",
            "the bishop cautioned the congregation against cheating in competitions.\n",
            "abantu baaaaaawuuunuuuuuuuuuuuuuuun .\n",
            "\n",
            "** Example 4 **\n",
            "he came in third place with thirty votes.\n",
            "abantu bangi baaawuuuuutamu .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transformer = tf.keras.models.load_model(\"./best_models/nmt_transformer1.h5\")\n",
        "\n",
        "def translate_sentence(input_sentence):\n",
        "    batch_size = tf.shape(input_sentence)[0]\n",
        "\n",
        "    # Tokenize the encoder input.\n",
        "    encoder_input_tokens = eng_tokenizer(input_sentence).to_tensor(\n",
        "        shape=(None, MAX_SEQUENCE_LENGTH)\n",
        "    )\n",
        "\n",
        "    # Define a function that outputs the next token's probability given the\n",
        "    # input sequence.\n",
        "    def next(prompt, cache, index):\n",
        "        logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n",
        "        # Ignore hidden states for now; only needed for contrastive search.\n",
        "        hidden_states = None\n",
        "        return logits, hidden_states, cache\n",
        "\n",
        "    # Build a prompt of length 40 with a start token and padding tokens.\n",
        "    length = 40\n",
        "    start = tf.fill((batch_size, 1), lug_tokenizer.token_to_id(\"[START]\"))\n",
        "    pad = tf.fill((batch_size, length - 1), lug_tokenizer.token_to_id(\"[PAD]\"))\n",
        "    prompt = tf.concat((start, pad), axis=-1)\n",
        "\n",
        "    generated_tokens = keras_nlp.samplers.GreedySampler()(\n",
        "        next,\n",
        "        prompt,\n",
        "        end_token_id=lug_tokenizer.token_to_id(\"[END]\"),\n",
        "        index=1,  # Start sampling after start token.\n",
        "    )\n",
        "    generated_sentences = lug_tokenizer.detokenize(generated_tokens)\n",
        "    return generated_sentences\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for i in range(5):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = translate_sentence(tf.constant([input_sentence]))\n",
        "    translated = translated.numpy()[0].decode(\"utf-8\")\n",
        "    translated = (\n",
        "        translated.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "    print(f\"** Example {i} **\")\n",
        "    print(input_sentence)\n",
        "    print(translated)\n",
        "    print()"
      ],
      "id": "c8c942c5"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1533e7f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a2f678-90e7-4931-b05b-3725d8f453a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1 Score:  {'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.044444446>, 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.012592593>, 'f1_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.01902357>}\n",
            "ROUGE-2 Score:  {'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>, 'f1_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>}\n"
          ]
        }
      ],
      "source": [
        "rouge_1 = keras_nlp.metrics.RougeN(order=1)\n",
        "rouge_2 = keras_nlp.metrics.RougeN(order=2)\n",
        "\n",
        "for test_pair in test_pairs[:30]:\n",
        "    input_sentence = test_pair[0]\n",
        "    reference_sentence = test_pair[1]\n",
        "\n",
        "    translated_sentence = translate_sentence(tf.constant([input_sentence]))\n",
        "    translated_sentence = translated_sentence.numpy()[0].decode(\"utf-8\")\n",
        "    translated_sentence = (\n",
        "        translated_sentence.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    rouge_1(reference_sentence, translated_sentence)\n",
        "    rouge_2(reference_sentence, translated_sentence)\n",
        "\n",
        "print(\"ROUGE-1 Score: \", rouge_1.result())\n",
        "print(\"ROUGE-2 Score: \", rouge_2.result())"
      ],
      "id": "1533e7f8"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o-4SP2vDjKR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfb5b91-4c9d-4f3f-9581-bc32384d5984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: tf.Tensor(0.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "bleu = Bleu()\n",
        "\n",
        "for test_pair in test_pairs[:30]:\n",
        "    input_sentence = test_pair[0]\n",
        "    reference_sentence = test_pair[1]\n",
        "\n",
        "    translated_sentence = translate_sentence(tf.constant([input_sentence]))\n",
        "    translated_sentence = translated_sentence.numpy()[0].decode(\"utf-8\")\n",
        "    translated_sentence = (\n",
        "        translated_sentence.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    bleu.update_state([reference_sentence], [translated_sentence])\n",
        "\n",
        "score = bleu.result()\n",
        "print(\"BLEU Score:\", score)"
      ],
      "id": "o-4SP2vDjKR_"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}